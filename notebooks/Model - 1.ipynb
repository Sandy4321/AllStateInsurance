{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Create a basic model using only the continous features ?\n",
    "\n",
    "* How to deal with the continous features ?\n",
    "* How can we select continuous feature that actually relate with our target variable ?\n",
    "* Which model is suitable to deal with the continuous variables ?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "basepath = os.path.expanduser('~/Desktop/src/AllState_Claims_Severity/')\n",
    "sys.path.append(os.path.join(basepath, 'src'))\n",
    "\n",
    "np.random.seed(2016)\n",
    "\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test, sample_sub = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat((train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Numerical variables. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical features: 14\n",
      "Numerical Features: \n",
      "['cont1', 'cont10', 'cont11', 'cont12', 'cont13', 'cont14', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9']\n"
     ]
    }
   ],
   "source": [
    "numerical_features = [col for col in data.columns if 'cont' in col]\n",
    "print('Number of numerical features: {}'.format(len(numerical_features)))\n",
    "print('Numerical Features: \\n{}'.format(numerical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_features(X):\n",
    "    \"\"\"\n",
    "        \n",
    "    Modifications:\n",
    "\n",
    "    1. cont1: create a variable defining frequency count of the variable\n",
    "    2. cont2: create a categorical variable out of it.\n",
    "    3. cont3: create a categorical variable out of it.\n",
    "    4. cont6: create a variable defining frequency count of the variable.\n",
    "    5. cont7: create a variable defining frequency count of the variable.\n",
    "    6. cont9: create a variable defining frequency count of the variable.\n",
    "    7. cont10: create a variable defining frequency count of the variable.\n",
    "    8. cont11: create a variable defining frequency count of the variable.\n",
    "    9. cont12: create a variable defining frequency count of the variable.\n",
    "    10.cont13: create a variable defining frequency count of the variable.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    X['cont1_count'] = X.groupby(['cont1'])['cont1'].transform(lambda x: len(x))\n",
    "    X['cont2_cat']   = X['cont2'].map(lambda x: np.round(x, decimals=1))\n",
    "    X['cont3_count'] = X.groupby(['cont3'])['cont3'].transform(lambda x: len(x))\n",
    "    X['cont6_count'] = X.groupby(['cont6'])['cont6'].transform(lambda x: len(x))\n",
    "    X['cont7_count'] = X.groupby(['cont7'])['cont7'].transform(lambda x: len(x))\n",
    "    X['cont9_count'] = X.groupby(['cont9'])['cont9'].transform(lambda x: len(x))\n",
    "    X['cont10_count'] = X.groupby(['cont10'])['cont10'].transform(lambda x: len(x))\n",
    "    X['cont11_count'] = X.groupby(['cont11'])['cont11'].transform(lambda x: len(x))\n",
    "    X['cont12_count'] = X.groupby(['cont12'])['cont12'].transform(lambda x: len(x))\n",
    "    X['cont13_count'] = X.groupby(['cont13'])['cont13'].transform(lambda x: len(x))\n",
    "    \n",
    "    return X\n",
    "        \n",
    "class ContinuousFeatureMorpher(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = create_features(X)\n",
    "        return X\n",
    "    \n",
    "class VarSelect(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, keys):\n",
    "        self.keys = keys\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        return df[self.keys]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature list\n",
    "feature_list = [\n",
    "    'cont1',\n",
    "    'cont1_count',\n",
    "    'cont2',\n",
    "    'cont2_cat',\n",
    "    'cont3',\n",
    "    'cont3_count',\n",
    "    'cont6',\n",
    "    'cont6_count',\n",
    "    'cont7',\n",
    "    'cont7_count',\n",
    "    'cont9',\n",
    "    'cont9_count',\n",
    "    'cont10',\n",
    "    'cont10_count',\n",
    "    'cont11',\n",
    "    'cont11_count',\n",
    "    'cont12',\n",
    "    'cont12_count',\n",
    "    'cont13',\n",
    "    'cont13_count'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ = data[:len(train)]\n",
    "test_  = data[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove instances with very high loss values\n",
    "mask_remove_outliers = train_.loss < 2e4\n",
    "\n",
    "train_ = train_[mask_remove_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into train and test set\n",
    "itr, ite = train_test_split(range(len(train_)), test_size=0.3, random_state=21386)\n",
    "\n",
    "Xtr = train_.iloc[itr][numerical_features]\n",
    "Xte = train_.iloc[ite][numerical_features]\n",
    "\n",
    "ytr = np.log(train_.iloc[itr]['loss'])\n",
    "yte = np.log(train_.iloc[ite]['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model definition\n",
    "pipeline_rf = Pipeline([(\n",
    "            'union', FeatureUnion([\n",
    "                    ('morpher', ContinuousFeatureMorpher()),\n",
    "                    ('var', VarSelect(keys=feature_list))\n",
    "                ])\n",
    "        ),\n",
    "        ('model', RandomForestRegressor(n_estimators=50, max_depth=7, n_jobs=-1, random_state=23137))\n",
    "        ])\n",
    "\n",
    "pipeline_xgbr = Pipeline([(\n",
    "            'union', FeatureUnion([\n",
    "                    ('morpher', ContinuousFeatureMorpher()),\n",
    "                    ('var', VarSelect(keys=feature_list))\n",
    "                ])\n",
    "        ),\n",
    "        ('model', xgb.XGBRegressor(seed=23123137))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv(train, target, estimators, **params):\n",
    "    kf = KFold(len(train), n_folds=params['n_folds'], shuffle=params['shuffle'], random_state=123731)\n",
    "    scores = []\n",
    "    \n",
    "    for i, (itr, ite) in enumerate(kf):\n",
    "        print('Fold: '.format(i))\n",
    "        \n",
    "        Xtr = train.iloc[itr]\n",
    "        Xte = train.iloc[ite]\n",
    "        \n",
    "        ytr = target.iloc[itr]\n",
    "        yte = target.iloc[ite]\n",
    "        \n",
    "        errors = []\n",
    "        yhats  = []\n",
    "        \n",
    "        for k, est in estimators.items():\n",
    "            print('Estimator: {}'.format(k))\n",
    "            \n",
    "            est.fit(Xtr, ytr)\n",
    "            yhat = np.exp(est.predict(Xte))\n",
    "            error = mean_absolute_error(np.exp(yte), yhat)\n",
    "            \n",
    "            yhats.append(yhat)\n",
    "            errors.append(error)\n",
    "            \n",
    "            print('MAE: {}'.format(error))\n",
    "            \n",
    "        ensemble_yhat  = gmean(yhats)\n",
    "        ensemble_score = mean_absolute_error(np.exp(yte), ensemble_yhat) \n",
    "        print('Ensemble MAE: {}'.format(ensemble_score))\n",
    "        print('-'*50+'\\n')\n",
    "        \n",
    "        scores.append(ensemble_score)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: \n",
      "Estimator: RandomForestRegressor\n",
      "MAE: 1710.8088283159805\n",
      "Estimator: XGBoostRegressor\n",
      "MAE: 1708.1254922427784\n",
      "Ensemble MAE: 1708.4919552260162\n",
      "--------------------------------------------------\n",
      "\n",
      "Fold: \n",
      "Estimator: RandomForestRegressor\n",
      "MAE: 1719.64414114493\n",
      "Estimator: XGBoostRegressor\n",
      "MAE: 1716.3023026043495\n",
      "Ensemble MAE: 1716.9879330906203\n",
      "--------------------------------------------------\n",
      "\n",
      "Fold: \n",
      "Estimator: RandomForestRegressor\n",
      "MAE: 1737.9925495270613\n",
      "Estimator: XGBoostRegressor\n",
      "MAE: 1735.81144343213\n",
      "Ensemble MAE: 1735.76850945925\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1708.4919552260162, 1716.9879330906203, 1735.76850945925]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'n_folds': 3,\n",
    "    'shuffle': True\n",
    "}\n",
    "\n",
    "estimators = {\n",
    "    'RandomForestRegressor': pipeline_rf,\n",
    "    'XGBoostRegressor':      pipeline_xgbr\n",
    "}\n",
    "\n",
    "cv(Xtr, ytr, estimators, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on unseen examples: 1778.2843834427758\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(Xtr, ytr)\n",
    "preds = np.exp(pipeline.predict(Xte))\n",
    "print('MAE on unseen examples: {}'.format(mean_absolute_error(np.exp(yte), preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
