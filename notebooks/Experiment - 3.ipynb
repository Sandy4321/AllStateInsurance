{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Feature Interaction among categorical variables.\n",
    "```\n",
    "\n",
    "* Binary Encoding of the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "basepath = os.path.expanduser('~/Desktop/src/AllState_Claims_Severity/')\n",
    "sys.path.append(os.path.join(basepath, 'src'))\n",
    "\n",
    "np.random.seed(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(basepath, 'data/raw/train.csv'))\n",
    "test  = pd.read_csv(os.path.join(basepath, 'data/raw/test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate train and test\n",
    "data = pd.concat((train, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.log(train.loss) # log domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Encode categorical variables **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Some Helper Functions</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_input(X):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    X: data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    A Dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        if isinstance(X, list):\n",
    "            X = pd.DataFrame(np.array(X))\n",
    "        elif isinstance(X, (np.generic, np.ndarray)):\n",
    "            X = pd.DataFrame(X)\n",
    "        else:\n",
    "            raise ValueError('Unexpected input type: %s' % (str(type(X))))\n",
    "    return X\n",
    "\n",
    "def get_obj_cols(df):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ---------\n",
    "    \n",
    "    df: Dataframe\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    Features of type `object`\n",
    "    \"\"\"\n",
    "    \n",
    "    return df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OrdinalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Ordinal encoding uses a single column of integers to represent the classes. An optional mapping dict can be passed\n",
    "    in, in this case we use the knowledge that there is some true order to the classes themselves. Otherwise, the classes\n",
    "    are assumed to have no true order and integers are selected at random.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose: int\n",
    "        integer indicating verbosity of output. 0 for none.\n",
    "    cols: list\n",
    "        a list of columns to encode, if None, all string columns will be encoded\n",
    "    drop_invariant: bool\n",
    "        boolean for whether or not to drop columns with 0 variance\n",
    "    return_df: bool\n",
    "        boolean for whether to return a pandas DataFrame from transform (otherwise it will be a numpy array)\n",
    "    mapping: dict\n",
    "        a mapping of class to label to use for the encoding, optional.\n",
    "    impute_missing: bool\n",
    "        will impute missing categories with -1.\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> from category_encoders import OrdinalEncoder\n",
    "    >>> from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "    >>> bunch = fetch_20newsgroups_vectorized(subset=\"all\")\n",
    "    >>> X, y = bunch.data, bunch.target\n",
    "    >>> enc = OrdinalEncoder(return_df=False).fit(X, y)\n",
    "    >>> numeric_dataset = enc.transform(X)\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Contrast Coding Systems for categorical variables.  UCLA: Statistical Consulting Group. from\n",
    "    http://www.ats.ucla.edu/stat/r/library/contrast_coding.\n",
    "    .. [2] Gregory Carey (2003). Coding Categorical Variables, from\n",
    "    http://psych.colorado.edu/~carey/Courses/PSYC5741/handouts/Coding%20Categorical%20Variables%202006-03-03.pdf\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, verbose=0, mapping=None, cols=None, drop_invariant=False, return_df=True, impute_missing=True):\n",
    "        self.return_df = return_df\n",
    "        self.drop_invariant = drop_invariant\n",
    "        self.drop_cols = []\n",
    "        self.verbose = verbose\n",
    "        self.cols = cols\n",
    "        self.mapping = mapping\n",
    "        self.impute_missing = impute_missing\n",
    "        self._dim = None\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        \"\"\"Fit encoder according to X and y.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Target values.\n",
    "        Returns\n",
    "        -------\n",
    "        self : encoder\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "\n",
    "        # first check the type\n",
    "        X = convert_input(X)\n",
    "\n",
    "        self._dim = X.shape[1]\n",
    "\n",
    "        # if columns aren't passed, just use every string column\n",
    "        if self.cols is None:\n",
    "            self.cols = get_obj_cols(X)\n",
    "\n",
    "        _, categories = self.ordinal_encoding(X, mapping=self.mapping, cols=self.cols, impute_missing=self.impute_missing)\n",
    "        self.mapping = categories\n",
    "\n",
    "        # drop all output columns with 0 variance.\n",
    "        if self.drop_invariant:\n",
    "            self.drop_cols = []\n",
    "            X_temp = self.transform(X)\n",
    "            self.drop_cols = [x for x in X_temp.columns.values if X_temp[x].var() <= 10e-5]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Perform the transformation to new categorical data.\n",
    "        Will use the mapping (if available) and the column list (if available, otherwise every column) to encode the\n",
    "        data ordinally.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "        Returns\n",
    "        -------\n",
    "        p : array, shape = [n_samples, n_numeric + N]\n",
    "            Transformed values with encoding applied.\n",
    "        \"\"\"\n",
    "\n",
    "        if self._dim is None:\n",
    "            raise ValueError('Must train encoder before it can be used to transform data.')\n",
    "\n",
    "        # first check the type\n",
    "        X = convert_input(X)\n",
    "\n",
    "        # then make sure that it is the right size\n",
    "        if X.shape[1] != self._dim:\n",
    "            raise ValueError('Unexpected input dimension %d, expected %d' % (X.shape[1], self._dim, ))\n",
    "\n",
    "        if not self.cols:\n",
    "            return X\n",
    "\n",
    "        X, _ = self.ordinal_encoding(X, mapping=self.mapping, cols=self.cols, impute_missing=self.impute_missing)\n",
    "\n",
    "        if self.drop_invariant:\n",
    "            for col in self.drop_cols:\n",
    "                X.drop(col, 1, inplace=True)\n",
    "\n",
    "        if self.return_df:\n",
    "            return X\n",
    "        else:\n",
    "            return X.values\n",
    "\n",
    "    @staticmethod\n",
    "    def ordinal_encoding(X_in, mapping=None, cols=None, impute_missing=True):\n",
    "        \"\"\"\n",
    "        Ordinal encoding uses a single column of integers to represent the classes. An optional mapping dict can be passed\n",
    "        in, in this case we use the knowledge that there is some true order to the classes themselves. Otherwise, the classes\n",
    "        are assumed to have no true order and integers are selected at random.\n",
    "        \"\"\"\n",
    "\n",
    "        X = X_in.copy(deep=True)\n",
    "\n",
    "        if cols is None:\n",
    "            cols = X.columns.values\n",
    "\n",
    "        mapping_out = []\n",
    "        if mapping is not None:\n",
    "            for switch in mapping:\n",
    "                for category in switch.get('mapping'):\n",
    "                    X.loc[X[switch.get('col')] == category[0], switch.get('col')] = str(category[1])\n",
    "                if impute_missing:\n",
    "                    X[switch.get('col')].fillna(-1, inplace=True)\n",
    "                X[switch.get('col')] = X[switch.get('col')].astype(int).reshape(-1, )\n",
    "        else:\n",
    "            for col in cols:\n",
    "                categories = list(set(X[col].values))\n",
    "                np.random.shuffle(categories)\n",
    "                \n",
    "                for idx, val in enumerate(categories):\n",
    "                    X.loc[X[col] == val, col] = str(idx)\n",
    "\n",
    "                if impute_missing:\n",
    "                    X[col].fillna(-1, inplace=True)\n",
    "\n",
    "                X[col] = X[col].astype(int).reshape(-1, )\n",
    "\n",
    "                mapping_out.append({'col': col, 'mapping': [(x[1], x[0]) for x in list(enumerate(categories))]},)\n",
    "\n",
    "        return X, mapping_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BinaryEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose: int\n",
    "        integer indicating verbosity of output. 0 for none.\n",
    "    cols: list\n",
    "        a list of columns to encode, if None, all string columns will be encoded\n",
    "    drop_invariant: bool\n",
    "        boolean for whether or not to drop columns with 0 variance\n",
    "    return_df: bool\n",
    "        boolean for whether to return a pandas DataFrame from transform (otherwise it will be a numpy array)\n",
    "    Example\n",
    "    -------\n",
    "    >>> from category_encoders import BinaryEncoder\n",
    "    >>> from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "    >>> bunch = fetch_20newsgroups_vectorized(subset=\"all\")\n",
    "    >>> X, y = bunch.data, bunch.target\n",
    "    >>> enc = BinaryEncoder(return_df=False).fit(X, y)\n",
    "    >>> numeric_dataset = enc.transform(X)\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=0, cols=None, drop_invariant=False, return_df=True):\n",
    "        self.return_df = return_df\n",
    "        self.drop_invariant = drop_invariant\n",
    "        self.drop_cols = []\n",
    "        self.verbose = verbose\n",
    "        self.cols = cols\n",
    "        self.ordinal_encoder = None\n",
    "        self._dim = None\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        \"\"\"Fit encoder according to X and y.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Target values.\n",
    "        Returns\n",
    "        -------\n",
    "        self : encoder\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "\n",
    "        # if the input dataset isn't already a dataframe, convert it to one (using default column names)\n",
    "        # first check the type\n",
    "        X = convert_input(X)\n",
    "\n",
    "        self._dim = X.shape[1]\n",
    "\n",
    "        # if columns aren't passed, just use every string column\n",
    "        if self.cols is None:\n",
    "            self.cols = get_obj_cols(X)\n",
    "\n",
    "        # train an ordinal pre-encoder\n",
    "        self.ordinal_encoder = OrdinalEncoder(verbose=self.verbose, cols=self.cols)\n",
    "        self.ordinal_encoder = self.ordinal_encoder.fit(X)\n",
    "\n",
    "        # drop all output columns with 0 variance.\n",
    "        if self.drop_invariant:\n",
    "            self.drop_cols = []\n",
    "            X_temp = self.transform(X)\n",
    "            self.drop_cols = [x for x in X_temp.columns.values if X_temp[x].var() <= 10e-5]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Perform the transformation to new categorical data.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "        Returns\n",
    "        -------\n",
    "        p : array, shape = [n_samples, n_numeric + N]\n",
    "            Transformed values with encoding applied.\n",
    "        \"\"\"\n",
    "\n",
    "        if self._dim is None:\n",
    "            raise ValueError('Must train encoder before it can be used to transform data.')\n",
    "\n",
    "        # first check the type\n",
    "        X = convert_input(X)\n",
    "\n",
    "        # then make sure that it is the right size\n",
    "        if X.shape[1] != self._dim:\n",
    "            raise ValueError('Unexpected input dimension %d, expected %d' % (X.shape[1], self._dim, ))\n",
    "\n",
    "        if not self.cols:\n",
    "            return X\n",
    "\n",
    "        X = self.ordinal_encoder.transform(X)\n",
    "\n",
    "        X = self.binary(X, cols=self.cols)\n",
    "\n",
    "        if self.drop_invariant:\n",
    "            for col in self.drop_cols:\n",
    "                X.drop(col, 1, inplace=True)\n",
    "\n",
    "        if self.return_df:\n",
    "            return X\n",
    "        else:\n",
    "            return X.values\n",
    "\n",
    "    def binary(self, X_in, cols=None):\n",
    "        \"\"\"\n",
    "        Binary encoding encodes the integers as binary code with one column per digit.\n",
    "        \"\"\"\n",
    "\n",
    "        X = X_in.copy(deep=True)\n",
    "\n",
    "        if cols is None:\n",
    "            cols = X.columns.values\n",
    "            pass_thru = []\n",
    "        else:\n",
    "            pass_thru = [col for col in X.columns.values if col not in cols]\n",
    "\n",
    "        bin_cols = []\n",
    "        for col in cols:\n",
    "            # figure out how many digits we need to represent the classes present\n",
    "            digits = int(np.ceil(np.log2(len(X[col].unique()))))\n",
    "\n",
    "            # map the ordinal column into a list of these digits, of length digits\n",
    "            X[col] = X[col].map(lambda x: self.col_transform(x, digits))\n",
    "\n",
    "            for dig in range(digits):\n",
    "                X[str(col) + '_%d' % (dig, )] = X[col].map(lambda r: int(r[dig]) if r is not None else None)\n",
    "                bin_cols.append(str(col) + '_%d' % (dig, ))\n",
    "\n",
    "        X = X.reindex(columns=bin_cols + pass_thru)\n",
    "\n",
    "        return X\n",
    "\n",
    "    @staticmethod\n",
    "    def col_transform(col, digits):\n",
    "        \"\"\"\n",
    "        The lambda body to transform the column values\n",
    "        \"\"\"\n",
    "\n",
    "        if col is None or float(col) < 0.0:\n",
    "            return None\n",
    "        else:\n",
    "\n",
    "            col = list(\"{0:b}\".format(int(col)))\n",
    "            if len(col) == digits:\n",
    "                return col\n",
    "            else:\n",
    "                return [0 for _ in range(digits - len(col))] + col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_columns = [col for col in train.columns if 'cat' in col]\n",
    "binary = BinaryEncoder(cols=categorical_columns, return_df=False)\n",
    "enc = binary.fit(train[categorical_columns], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cont_columns = [col for col in train.columns if 'cont' in col]\n",
    "X_ = pd.concat( (pd.DataFrame(X), train[cont_columns] ), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188318, 243)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Split into training and test sets **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itrain, itest = train_test_split(range(len(train)), test_size=.2, random_state=12121)\n",
    "\n",
    "X_train = X_.values[itrain]\n",
    "X_test  = X_.values[itest]\n",
    "\n",
    "y_train = y.values[itrain]\n",
    "y_test  = y.values[itest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "MAE score: 1167.3550020405903\n",
      "Fold: 1\n",
      "MAE score: 1152.3667856184145\n",
      "Fold: 2\n",
      "MAE score: 1161.5399681130748\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(len(X_train), n_folds=3, shuffle=True, random_state=1231)\n",
    "\n",
    "for index, (itr, ite) in enumerate(kf):\n",
    "    print('Fold: {}'.format(index))\n",
    "    \n",
    "    Xtr = X_train[itr]\n",
    "    ytr = y_train[itr]\n",
    "    \n",
    "    Xte = X_train[ite]\n",
    "    yte = y_train[ite]\n",
    "    \n",
    "#     est = RandomForestRegressor(n_jobs=-1, random_state=1231831)\n",
    "    est = xgb.XGBRegressor(n_estimators=325, gamma=0.5290, min_child_weight=4.2922, subsample=0.99, colsample_bytree=0.3, max_depth=7, seed=12313)\n",
    "    est.fit(Xtr, ytr)\n",
    "    \n",
    "    yhat = est.predict(Xte)\n",
    "    \n",
    "    print('MAE score: {}'.format(mean_absolute_error(np.exp(yte), np.exp(yhat))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1137.9178118975565\n"
     ]
    }
   ],
   "source": [
    "# est = RandomForestRegressor(n_jobs=-1, random_state=1231319)\n",
    "est = xgb.XGBRegressor(n_estimators=325, gamma=0.5290, min_child_weight=4.2922, subsample=0.99, colsample_bytree=0.3, max_depth=7, seed=12313)\n",
    "est.fit(X_train, y_train)\n",
    "pred = est.predict(X_test)\n",
    "\n",
    "print('Mean Absolute Error: {0}'.format(mean_absolute_error(np.exp(y_test), np.exp(pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_test = BinaryEncoder(cols=categorical_columns, return_df=False)\n",
    "enc = binary.fit(test[categorical_columns], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
